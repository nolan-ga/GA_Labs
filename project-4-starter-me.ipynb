{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with stumbleupon data\n",
    "\n",
    "Project 4 has been changed since scraping was untenable. The project now focuses on the stumbleupon kaggle dataset. For more information on this dataset, [check out the website here](https://www.kaggle.com/c/stumbleupon).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the dataset\n",
    "\n",
    "This is the only part completed for you.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su = pd.read_csv('../dataset/evergreen.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>is_news</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  ...    is_news  lengthyLinkDomain  \\\n",
       "0           0.047059           0.023529  ...          1                  1   \n",
       "\n",
       "   linkwordscore  news_front_page  non_markup_alphanum_characters  \\\n",
       "0             24                0                            5424   \n",
       "\n",
       "   numberOfLinks  numwords_in_url parametrizedLinkRatio  \\\n",
       "0            170                8              0.152941   \n",
       "\n",
       "   spelling_errors_ratio  label  \n",
       "0                0.07913      0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean up/examine your data\n",
    "\n",
    "Some of the columns may have values that need changing or that are of the wrong type. There could also be columns that aren't very useful.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    27\n",
      "dtype: int64\n",
      "False    7395\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for nulls\n",
    "\n",
    "print su.isnull().any(axis = 0).value_counts()\n",
    "print su.isnull().any(axis = 1).value_counts()\n",
    "\n",
    "# As you can see below, no nulls... yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert alchemy_category_score\n",
    "\n",
    "su.alchemy_category_score = pd.to_numeric(su.alchemy_category_score, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the NaNs you created in the previous line of code\n",
    "\n",
    "su = su.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert is_news and fill '?'s with '0'\n",
    "\n",
    "su.is_news = pd.to_numeric(su.is_news, errors='coerce')\n",
    "su.is_news = su.is_news.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert news_front_page and fill '?'s with '0'\n",
    "\n",
    "su.news_front_page = pd.to_numeric(su.news_front_page, errors='coerce')\n",
    "su.news_front_page = su.news_front_page.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5053, 27)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "\n",
    "su.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Note*__ \n",
    "\n",
    "For the sake of concision, I will not show the pairplots I created to view relationships between the numeric data and target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use sklearn to evaluate variable significance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Run a logistic regression predicting evergreen from the numeric columns\n",
    "\n",
    "And print out the results as shown in the example above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List numeric features\n",
    "\n",
    "numeric_features = ['avglinksize', 'alchemy_category_score', 'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3', \n",
    "                    'commonlinkratio_4', 'compression_ratio', 'embed_ratio', 'is_news', 'framebased', \n",
    "                    'frameTagRatio', 'numwords_in_url', 'lengthyLinkDomain', 'linkwordscore', 'numberOfLinks', \n",
    "                    'numwords_in_url', 'parametrizedLinkRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "\n",
    "X = su[numeric_features]\n",
    "y = su.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Create training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3789, 17)\n",
      "(3789,)\n",
      "(1264, 17)\n",
      "(1264,)\n"
     ]
    }
   ],
   "source": [
    "# Confirm shape of train and test sets\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize X\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit a logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "pred_class = logreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.614715189873\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score of train_test_split on numeric data\n",
    "\n",
    "from sklearn import metrics\n",
    "print \"Accuracy Score:\"\n",
    "print metrics.accuracy_score(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve\n",
      "0.59518473956\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC curve\n",
    "\n",
    "# First predict probabilities for evergreen\n",
    "probs = logreg.predict_proba(X_test)\n",
    "\n",
    "# Next print auc_score, which is area under ROC curve\n",
    "print \"Area under ROC curve\"\n",
    "print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Run a logistic regression predicting evergreen from the numeric columns and a categorical variable of alchemy_category\n",
    "\n",
    "And print out the results as shown in the example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummy variables for alchemy_category\n",
    "\n",
    "dummy_alc = pd.get_dummies(su.alchemy_category, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attach dummy variable DataFrame to numeric features\n",
    "\n",
    "su_new = su[numeric_features].join(dummy_alc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reinstantiate logistic regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "X = su_new[su_new.columns]\n",
    "y = su.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit model on normalized data\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "pred_class = logreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.669303797468\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy score\n",
    "\n",
    "print \"Accuracy Score:\"\n",
    "print metrics.accuracy_score(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve:\n",
      "0.609984602481\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC curve\n",
    "\n",
    "# First predict probabilities for evergreen\n",
    "probs = logreg.predict_proba(X_test)\n",
    "\n",
    "# Next print auc_score, which is area under ROC curve\n",
    "print \"Area under ROC curve:\"\n",
    "print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a shot at confusion matrix\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, pred_class)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score:\n",
      "0.708661417323\n"
     ]
    }
   ],
   "source": [
    "# Print out recall - of all the positives, how many did you predict?\n",
    "\n",
    "print \"Recall score:\"\n",
    "print metrics.recall_score(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Findings:*__\n",
    "\n",
    "Although accuracy score and recall score are reasonably high, the area under the ROC curve is .61, only marginally better than the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use sklearn to cross-validate the accuracy of the model above\n",
    "\n",
    "Normalize the numeric and categorical columns of the predictor matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize X for cross validation\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross_val score (accuracy)\n",
      "0.677025789535\n"
     ]
    }
   ],
   "source": [
    "# Import necessary module\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "print \"Mean cross_val score (accuracy)\"\n",
    "print cross_val_score(logreg, X_scaled, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Findings*__\n",
    "\n",
    "Cross validating lowered the accuracy score by .01, providing a more durable accuracy score than that provided through the train_test_split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gridsearch regularization parameters for logistic regression\n",
    "\n",
    "Find the best regularization type (Ridge, Lasso) across a set of regularization strengths.\n",
    "\n",
    "[NOTE: C is the inverse of the regularization strength. Lower C values are stronger regularization. Having a C higher than 1 will significantly slow down the search. I'm not particularly interested in values over 1, since this is the default regularization strength in LogisticRegression.]\n",
    "\n",
    "**After you find the best set of parameters, build a Logistic Regression with those parameters and crossvalidate the score.**\n",
    "\n",
    "[NOTE 2: to run Lasso regularization the solver should be `'liblinear'`]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross_val score (accuracy):\n",
      "0.679601220992\n"
     ]
    }
   ],
   "source": [
    "# Before running a gridsearch, play with L1 and L2\n",
    "# First L1\n",
    "\n",
    "logreg_L1 = LogisticRegression(C=0.1, penalty='l1') \n",
    "\n",
    "# Cross validation score \n",
    "\n",
    "print \"Mean cross_val score (accuracy):\"\n",
    "print cross_val_score(logreg_L1, X_scaled, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross_val score (accuracy):\n",
      "0.677420263766\n"
     ]
    }
   ],
   "source": [
    "# Before running a gridsearch, play with L1 and L2\n",
    "# Next L2\n",
    "\n",
    "logreg_L2 = LogisticRegression(C = 0.1, penalty = 'l2')\n",
    "\n",
    "# Cross validation score\n",
    "\n",
    "print \"Mean cross_val score (accuracy):\"\n",
    "print cross_val_score(logreg_L2, X_scaled, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Reinstantiate logreg\n",
    "logreg_for_grid = LogisticRegression()\n",
    "\n",
    "# Generate C_range\n",
    "C_range = [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0]\n",
    "\n",
    "# Penalty options include l1 and l2\n",
    "penalty_options = ['l1', 'l2']\n",
    "\n",
    "# Create parameter space\n",
    "# param_grid = dict(logisticregression__C = C_range, logisticregression__penalty = penalty_options)\n",
    "parameters = {'C':[.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0], 'penalty':['l1', 'l2']}\n",
    "\n",
    "# Use 10-fold cross validation in grid search\n",
    "grid = GridSearchCV(logreg_for_grid, param_grid = parameters, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit model\n",
    "grid.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score derived from the grid search:\n",
      "0.679596279438\n",
      "\n",
      "\n",
      "Best parameters derived from the grid search:\n",
      "{'penalty': 'l1', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Examine the best model\n",
    "\n",
    "print \"Best cross validation score derived from the grid search:\"\n",
    "print grid.best_score_\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Best parameters derived from the grid search:\"\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Findings*__\n",
    "\n",
    "Using C and penalty as parameters to refine in the grid search, running GridSearchCV produced optimal penalty: L1, and optimal C: 0.1. The best cross validation score from the grid search was 0.67, almost identical to pre-grid search cross validation scores I derived above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gridsearch neighbors for kNN\n",
    "\n",
    "Find the best number of neighbors with your predictors to predict the `label` target variable.\n",
    "\n",
    "Start by bulding a kNN model with a set number of neighbors, then use gridsearch to run through a series of neighbors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*NOTE TO SELF: GridSearchCV will automatically perform a cross validation for you*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Begin by importing necessary modules and instantiating KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify k_range\n",
    "\n",
    "k_range = range(1, 31)\n",
    "\n",
    "# Create dictionary for grid search\n",
    "\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "# Instantiate the grid\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy')\n",
    "\n",
    "# Fit grid to data\n",
    "\n",
    "grid.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697407480705\n",
      "{'n_neighbors': 24}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Findings*__\n",
    "\n",
    "KNN grid search produced a slightly better accuracy score than the logistic regression grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Choose a new target from alchemy_category to predict with logistic regression\n",
    "\n",
    "**Ideally your category choice will have a small fraction of the total rows, but not TOO small!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Note*__\n",
    "\n",
    "I've chosen \"science_technology\" as my new target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Chose your target category, create the Y vector, and check the fraction of instances\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recreation            1229\n",
       "arts_entertainment     941\n",
       "business               880\n",
       "health                 506\n",
       "sports                 380\n",
       "culture_politics       343\n",
       "computer_internet      296\n",
       "science_technology     289\n",
       "gaming                  76\n",
       "religion                72\n",
       "law_crime               31\n",
       "unknown                  6\n",
       "weather                  4\n",
       "Name: alchemy_category, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View value_counts of alchemy_categories\n",
    "\n",
    "su.alchemy_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose \"science and technology\" as the category to use as target\n",
    "\n",
    "su['sci_or_not'] = su.alchemy_category.map({'science_technology':1, 'business':0, 'recreation':0, \n",
    "                                            'health':0, 'sports':0, 'arts_entertainment':0,\n",
    "                                            'gaming':0, 'culture_politics':0, 'computer_internet':0, \n",
    "                                            'law_crime':0, 'religion':0, 'weather':0, 'unknown':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>sci_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "\n",
       "   alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0                0.789131     2.055556           0.676471           0.205882   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4     ...      lengthyLinkDomain  \\\n",
       "0           0.047059           0.023529     ...                      1   \n",
       "\n",
       "   linkwordscore  news_front_page  non_markup_alphanum_characters  \\\n",
       "0             24              0.0                            5424   \n",
       "\n",
       "   numberOfLinks  numwords_in_url  parametrizedLinkRatio  \\\n",
       "0            170                8               0.152941   \n",
       "\n",
       "   spelling_errors_ratio  label  sci_or_not  \n",
       "0                0.07913      0           0  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View head of new DataFrame with target column \"sci_or_not\"\n",
    "\n",
    "su.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate Step - perform cross validation on new features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build features and target\n",
    "\n",
    "features = ['avglinksize', 'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3', \n",
    "                    'commonlinkratio_4', 'compression_ratio', 'embed_ratio', 'is_news', 'framebased', \n",
    "                    'frameTagRatio', 'numwords_in_url', 'lengthyLinkDomain', 'linkwordscore', 'numberOfLinks', \n",
    "                    'numwords_in_url', 'parametrizedLinkRatio', 'alchemy_category_score', 'label']\n",
    "\n",
    "X = su[features]\n",
    "y = su.sci_or_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross_val score (accuracy):\n",
      "0.942806671972\n"
     ]
    }
   ],
   "source": [
    "# Instantiate logreg\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "print \"Mean cross_val score (accuracy):\"\n",
    "print cross_val_score(logreg, X_scaled, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Gridsearch a logistic regression to predict accuracy on your new target from the interaction predictors\n",
    "\n",
    "Include Ridge and Lasso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "# Already done from first Grid Search\n",
    "\n",
    "# Reinstantiate logreg\n",
    "logreg_for_grid = LogisticRegression()\n",
    "\n",
    "# Penalty options include l1 and l2\n",
    "penalty_options = ['l1', 'l2']\n",
    "\n",
    "# Create parameter space\n",
    "parameters = {'C':[.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0], 'penalty':['l1', 'l2']}\n",
    "\n",
    "# Use 10-fold cross validation in grid search\n",
    "grid = GridSearchCV(logreg_for_grid, param_grid = parameters, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit model\n",
    "grid.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score derived from the grid search:\n",
      "0.942806253711\n",
      "\n",
      "\n",
      "Best parameters derived from the grid search:\n",
      "{'penalty': 'l1', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Examine the best model\n",
    "\n",
    "print \"Best cross validation score derived from the grid search:\"\n",
    "print grid.best_score_\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Best parameters derived from the grid search:\"\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Build a logistic regression with the optimal parameters, and look at the coefficients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of refined model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avglinksize</td>\n",
       "      <td>[0.0214403275306]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>commonlinkratio_1</td>\n",
       "      <td>[0.0974102160723]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commonlinkratio_2</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>commonlinkratio_3</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>commonlinkratio_4</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compression_ratio</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>embed_ratio</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is_news</td>\n",
       "      <td>[0.0284667838802]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>framebased</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>frameTagRatio</td>\n",
       "      <td>[0.121325784115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>numwords_in_url</td>\n",
       "      <td>[0.0261000468145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lengthyLinkDomain</td>\n",
       "      <td>[0.0687763315085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>linkwordscore</td>\n",
       "      <td>[-0.17151265533]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>numberOfLinks</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>numwords_in_url</td>\n",
       "      <td>[0.037316255832]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>parametrizedLinkRatio</td>\n",
       "      <td>[-0.0404086696249]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>alchemy_category_score</td>\n",
       "      <td>[-0.262933353816]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>label</td>\n",
       "      <td>[-0.114645419302]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                   1\n",
       "0              avglinksize   [0.0214403275306]\n",
       "1        commonlinkratio_1   [0.0974102160723]\n",
       "2        commonlinkratio_2               [0.0]\n",
       "3        commonlinkratio_3               [0.0]\n",
       "4        commonlinkratio_4               [0.0]\n",
       "5        compression_ratio               [0.0]\n",
       "6              embed_ratio               [0.0]\n",
       "7                  is_news   [0.0284667838802]\n",
       "8               framebased               [0.0]\n",
       "9            frameTagRatio    [0.121325784115]\n",
       "10         numwords_in_url   [0.0261000468145]\n",
       "11       lengthyLinkDomain   [0.0687763315085]\n",
       "12           linkwordscore    [-0.17151265533]\n",
       "13           numberOfLinks               [0.0]\n",
       "14         numwords_in_url    [0.037316255832]\n",
       "15   parametrizedLinkRatio  [-0.0404086696249]\n",
       "16  alchemy_category_score   [-0.262933353816]\n",
       "17                   label   [-0.114645419302]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a logistic regression with parameters determined above\n",
    "\n",
    "logreg_refined = LogisticRegression(C=0.1, penalty='l1') \n",
    "\n",
    "# Fit the model to features and target\n",
    "\n",
    "model = logreg_refined.fit(X_scaled, y)\n",
    "\n",
    "# Look at coefficients \n",
    "\n",
    "print \"Coefficients of refined model:\"\n",
    "\n",
    "pd.DataFrame(zip(features, np.transpose(model.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Gridsearch parameters for a logistic regression with the same target and predictors, but score based on precision rather than accuracy\n",
    "\n",
    "Look at the documentation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='average_precision',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "# Already done from first Grid Search\n",
    "\n",
    "# Reinstantiate logreg\n",
    "logreg_for_grid = LogisticRegression()\n",
    "\n",
    "# Penalty options include l1 and l2\n",
    "penalty_options = ['l1', 'l2']\n",
    "\n",
    "# Create parameter space\n",
    "parameters = {'C':[.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0], 'penalty':['l1', 'l2']}\n",
    "\n",
    "# Use 10-fold cross validation in grid search\n",
    "grid = GridSearchCV(logreg_for_grid, param_grid = parameters, cv=10, scoring='average_precision')\n",
    "\n",
    "# Fit model\n",
    "grid.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best precision score derived from the grid search:\n",
      "0.0787738983661\n",
      "\n",
      "\n",
      "Best parameters derived from the grid search:\n",
      "{'penalty': 'l2', 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Examine the best model\n",
    "\n",
    "print \"Best precision score derived from the grid search:\"\n",
    "print grid.best_score_\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Best parameters derived from the grid search:\"\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS] 8. Build models predicting from words\n",
    "\n",
    "This is a bit of the NLP we covered in the pipeline lecture!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Choose 'body' or 'title' from the boilerplate to be the basis of your word predictors\n",
    "\n",
    "You will need to parse the json from the boilerplate field.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Use CountVectorizer to create your predictor matrix from the string column\n",
    "\n",
    "It is up to you what range of ngrams and features, and whether or not you want the columns binary or counts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Gridsearch a logistic regression predicting accuracy of your chosen target category from word predictor matrix\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Do the same as above, but score the gridsearch based on precision rather than accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Build a logistic regression with optimal precision categories\n",
    "\n",
    "Print out the top 20 or 25 word features as ranked by their coefficients.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
